{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting pdfminer.six==20250506 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.3.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber) (3.4.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (25.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.22)\n",
            "Downloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytesseract, pypdfium2, pdf2image, pdfminer.six, pdfplumber\n",
            "Successfully installed pdf2image-1.17.0 pdfminer.six-20250506 pdfplumber-0.11.7 pypdfium2-4.30.0 pytesseract-0.3.13\n"
          ]
        }
      ],
      "source": [
        "%pip install pdfplumber pytesseract pdf2image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import pdfplumber\n",
        "import pytesseract\n",
        "from pdf2image import convert_from_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Text Extraction\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    try:\n",
        "        # Try direct text extraction\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                page_text = page.extract_text()\n",
        "                if page_text:\n",
        "                    text += page_text\n",
        "\n",
        "        if text.strip():\n",
        "            return text.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"Direct text extraction failed: {e}\")\n",
        "\n",
        "    # Fallback to OCR for image-based PDFs\n",
        "    print(\"Falling back to OCR for image-based PDF.\")\n",
        "    try:\n",
        "        images = convert_from_path(pdf_path)\n",
        "        for image in images:\n",
        "            page_text = pytesseract.image_to_string(image)\n",
        "            text += page_text + \"\\n\"\n",
        "    except Exception as e:\n",
        "        print(f\"OCR failed: {e}\")\n",
        "\n",
        "    return text.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracted Text from PDF:\n",
            "Dhvani Kakadiya\n",
            "/envel⌢pedhvani1215@gmail.com ♂phone-alt+91 9773001459 ὑ7Leetcode /linkedin-inLinkedin /githubGithub\n",
            "EDUCATION\n",
            "Gujarat Technological University Expected May 2026\n",
            "Bachelor of Technology in Computer Engineering CPI: 9.17\n",
            "The Radiant International School, Surat 2022\n",
            "Board of Higher Secondary Education - GSEB Percentage: 90.78\n",
            "Technologies\n",
            "Languages: Java,C,MySQL,Python,Javascript,Dart,ruby(Basic),Javascript,HTML/CSS,PHP,Bootstrap/Tailwind\n",
            "Technologies: Firebase,Machine learning,Data analysis,Reactjs\n",
            "Version Control: Git,GitHub\n",
            "Tools: VS Code,Android Studio,Docker,Xampp,Apache netbeans,Google Colab,Anaconda,Jupyter Notebook,nmap,MongoDB\n",
            "compass\n",
            "Soft Skills: Communication,Problem solving,Teamwork,concentration\n",
            "PROJECTS\n",
            "Eklavy – API based Language Learning Website\n",
            "Technologies used - React , Tailwind CSS, Shadcn UI, Firebase , React Router2024\n",
            "◦Implemented features such as a dynamic different language catalog, quiz, progress tracking,sign up and login\n",
            "facility, and a light/dark theme switcher. Used React Hooks and Context API for efficient state management.\n",
            "◦Optimized for both desktop and mobile platforms. Also use react Hooks, Context API, Lazy Loading,\n",
            "Suspense and firebase for Authentication,Firestore,real time dataset and hosting\n",
            "Code Compiler - Online Code Editor Runner\n",
            "Technologies used - React, Tailwind CSS, Shadcn UI, Code Execution API, JavaScript,Monaco\n",
            "Editor, Axios, React Router2025\n",
            "◦Designed and implemented an interactive online code editor that allows real-time execution of multiple\n",
            "programming languages directly in the browser.Integrated a code execution API to allow users to write,\n",
            "run, and debug code instantly.\n",
            "◦Features include syntax highlighting, AI-based code suggestions, dark/light theme toggle, and shareable\n",
            "code snippets via generated links. Fully responsive across all devices.\n",
            "Dhvtisu – Online Services Provider\n",
            "Technologies used - Core PHP,MySQL,HTML5,Javascript,Tailwind css,AJAX2025\n",
            "◦Implemented features like Home page,Services ,Feature Section that highlights available services, Portfolio\n",
            "Dynamic gallery to display past work and projects with descriptions,write blogs and reviews about services,\n",
            "user authentication for service consumer and service provider and a Ai chatboat for solve queries\n",
            "◦Backend built with modular PHP structure, including admin panel, user dashboard, and content manage-\n",
            "ment for services and blogs. Focused on secure code practices, including input sanitization, session timeout\n",
            "handling, and role-based access control (RBAC).\n",
            "Face Recognition System – Real-time Identity Verification\n",
            "Technologies Used:Python,OpenCV,HaarCascades,Dlib,FaceNet,NumPy,Tkinter,scikit-\n",
            "learn,SQLite,Matplotlib2025\n",
            "◦Developed a robust face recognition system that detects and identifies individuals in real-time using computer\n",
            "vision and machine learning.\n",
            "◦This project leverages OpenCV for face detection and deep learning models for facial recognition, enabling\n",
            "secure, contactless identification. Integrated a user-friendly interface for enrollment, authentication, and\n",
            "attendance tracking.\n",
            "Achievements & Certifications\n",
            "◦Certificate of Completion from Google – Web Development Workshop of Google Developer Group\n",
            "◦Certificate of Completion from Forage – JPMorgan Chase & Co.- Cybersecurity security\n",
            "◦Certificate of Completion from Google – Azure AI Services in Develop natural language Processing\n",
            "◦Certificate of Completion from Microsoft Learn Student Ambassador – Web Development Wrokshop\n",
            "◦Certified Web Development internship program at Zidio Development\n",
            "RELEVENT COURSEWORK\n",
            "•Data Structures & Algorithms •Computer Networks\n",
            "•Object-Oriented Programming •Software Engineering\n",
            "•Operating Systems •Database Management\n",
            "•Theory of computation\n"
          ]
        }
      ],
      "source": [
        "# File Path\n",
        "pdf_path = \"/content/drive/MyDrive/Resume project/Resume.pdf\"\n",
        "resume_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "# Extract Text from PDF\n",
        "print(\"\\nExtracted Text from PDF:\")\n",
        "print(resume_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "response:\n",
            "GenerateContentResponse(\n",
            "    done=True,\n",
            "    iterator=None,\n",
            "    result=protos.GenerateContentResponse({\n",
            "      \"candidates\": [\n",
            "        {\n",
            "          \"content\": {\n",
            "            \"parts\": [\n",
            "              {\n",
            "                \"text\": \"Google is owned by Alphabet Inc. Google was reorganized under this new parent company in 2015.\\n\"\n",
            "              }\n",
            "            ],\n",
            "            \"role\": \"model\"\n",
            "          },\n",
            "          \"finish_reason\": \"STOP\",\n",
            "          \"avg_logprobs\": -0.36393692182457965\n",
            "        }\n",
            "      ],\n",
            "      \"usage_metadata\": {\n",
            "        \"prompt_token_count\": 6,\n",
            "        \"candidates_token_count\": 23,\n",
            "        \"total_token_count\": 29\n",
            "      },\n",
            "      \"model_version\": \"gemini-2.0-flash\"\n",
            "    }),\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Print Response\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Google is owned by Alphabet Inc. Google was reorganized under this new parent company in 2015.\n",
            "\n",
            "\n",
            "Model Version: gemini-2.0-flash\n"
          ]
        }
      ],
      "source": [
        "# Get Text Response\n",
        "print(response.text)\n",
        "\n",
        "# Get Model Version\n",
        "print(f\"\\nModel Version: {response.model_version}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "job_description = \"\"\"\n",
        "We are seeking a passionate and knowledgeable AI/ML instructor with a minimum of 1.5 years of experience in training students or professionals in artificial intelligence and machine learning. The ideal candidate should combine hands-on technical expertise with the ability to deliver engaging and insightful training sessions.\n",
        "\n",
        "Key Responsibilities:\n",
        "\n",
        "Deliver hands-on training programs in AI/ML for learners including students, working professionals, and corporate teams.\n",
        "Design curriculum content, project work, assessments, and resource materials related to AI and ML domains.\n",
        "Effectively explain core AI/ML topics such as supervised vs. unsupervised learning, reinforcement learning, deep learning, NLP, computer vision, and generative models.\n",
        "Guide participants in building ML models using Python and tools like TensorFlow, PyTorch, Scikit-learn, OpenCV, and NLP libraries.\n",
        "Mentor learners on their capstone projects and help them build real-world AI/ML solutions.\n",
        "Stay current with emerging trends in AI/ML and continuously enhance training content and examples.\n",
        "Facilitate interactive lab sessions, coding challenges, and live demonstrations to reinforce theoretical learning.\n",
        "Assess learner performance, provide personalized feedback, and support skill enhancement.\n",
        "Support learners with industry use cases, career guidance, and preparation for relevant certifications.\n",
        "\n",
        "Required Skills:\n",
        "\n",
        "Strong conceptual understanding of AI, data science, machine learning, and deep learning techniques.\n",
        "Hands-on experience with Python programming and related ML libraries such as NumPy, Pandas, Matplotlib, TensorFlow, PyTorch, OpenCV, and NLP tools.\n",
        "Proven track record of teaching or mentoring individuals in AI/ML domains.\n",
        "Excellent verbal communication and presentation skills.\n",
        "Ability to simplify and communicate complex technical topics to diverse audiences.\n",
        "Familiarity with cloud-based platforms like AWS, Azure, or GCP, and environments like Google Colab, Kaggle, and Jupyter.\n",
        "Knowledge of model deployment using Flask, FastAPI, or Streamlit is a plus.\n",
        "Understanding of Generative AI concepts, including ChatGPT or other large language models, is desirable.\n",
        "\n",
        "Qualifications:\n",
        "\n",
        "Bachelor’s or Master’s degree in Computer Science, Artificial Intelligence, Data Science, or a related technical field.\n",
        "\n",
        "Certifications in AI/ML (e.g., TensorFlow Developer, AWS Machine Learning, Coursera ML Specialization) are a strong advantage.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google.generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google.generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google.generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google.generativeai) (2.177.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google.generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google.generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google.generativeai) (2.11.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google.generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google.generativeai) (4.14.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google.generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google.generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google.generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google.generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google.generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google.generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google.generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google.generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google.generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google.generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google.generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google.generativeai) (0.4.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google.generativeai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google.generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google.generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google.generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (2025.7.14)\n"
          ]
        }
      ],
      "source": [
        "%pip install google.generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import Library\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Set-Up API Key\n",
        "api_key = \"#\"\n",
        "\n",
        "# Configure GenerativeAI\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "# Use the model\n",
        "model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
        "response = model.generate_content(\"Who is Owner of Google?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "response:\n",
            "GenerateContentResponse(\n",
            "    done=True,\n",
            "    iterator=None,\n",
            "    result=protos.GenerateContentResponse({\n",
            "      \"candidates\": [\n",
            "        {\n",
            "          \"content\": {\n",
            "            \"parts\": [\n",
            "              {\n",
            "                \"text\": \"Google is owned by Alphabet Inc. Google was reorganized under this new parent company in 2015.\\n\"\n",
            "              }\n",
            "            ],\n",
            "            \"role\": \"model\"\n",
            "          },\n",
            "          \"finish_reason\": \"STOP\",\n",
            "          \"avg_logprobs\": -0.36393692182457965\n",
            "        }\n",
            "      ],\n",
            "      \"usage_metadata\": {\n",
            "        \"prompt_token_count\": 6,\n",
            "        \"candidates_token_count\": 23,\n",
            "        \"total_token_count\": 29\n",
            "      },\n",
            "      \"model_version\": \"gemini-2.0-flash\"\n",
            "    }),\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Print Response\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Google is owned by Alphabet Inc. Google was reorganized under this new parent company in 2015.\n",
            "\n",
            "\n",
            "Model Version: gemini-2.0-flash\n"
          ]
        }
      ],
      "source": [
        "# Get Text Response\n",
        "print(response.text)\n",
        "\n",
        "# Get Model Version\n",
        "print(f\"\\nModel Version: {response.model_version}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_resume(resume_text):\n",
        "    if not resume_text:\n",
        "        return {\"error\": \"Resume text is required for analysis.\"}\n",
        "\n",
        "    model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
        "\n",
        "    base_prompt = f\"\"\"\n",
        "    You are an experienced HR with technical knowledge in one of these roles: Data Scientist, Data Analyst, DevOps Engineer, Machine Learning Engineer, Prompt Engineer, AI Engineer, Full Stack Web Developer, Big Data Engineer, Marketing Analyst, HR Manager, or Software Developer; review the provided resume and give a professional assessment on job fit, list existing skills, suggest skills to improve, recommend relevant courses, and highlight key strengths and weaknesses.\n",
        "\n",
        "    Resume:\n",
        "    {resume_text}\n",
        "    \"\"\"\n",
        "\n",
        "    response = model.generate_content(base_prompt)\n",
        "\n",
        "    analysis = response.text.strip()\n",
        "    return analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Okay, here's my assessment of Dhvani Kakadiya's resume, focusing on potential job fits and areas for improvement.  I'll assess her suitability primarily for roles like **Software Developer (especially Front-End or Full-Stack)**, but will also touch on overlaps with Data Analysis/ML roles.\n",
            "\n",
            "**Overall Impression:**\n",
            "\n",
            "Dhvani presents a well-structured resume highlighting a strong academic record, a good breadth of technical skills, and hands-on project experience. The projects demonstrate a proactive approach to learning and applying her skills. The resume leans heavily into web development, but shows some aptitude and interest in data science/ML.\n",
            "\n",
            "**Job Fit Assessment:**\n",
            "\n",
            "*   **Strong Fit:**\n",
            "    *   **Front-End Developer:** Her proficiency in React, JavaScript, HTML/CSS, Tailwind CSS, and experience with UI libraries (Shadcn UI) and state management (React Hooks, Context API) make her a strong candidate for front-end roles. The Eklavy and Code Compiler projects are particularly relevant.\n",
            "    *   **Full-Stack Developer:** The resume demonstrates full-stack capabilities with experience in front-end technologies and back-end technologies like PHP, MySQL, Firebase, and experience with databases. The Dhvtisu project highlights her ability to build a complete web application with user authentication and a backend admin panel.\n",
            "    *   **Entry-Level Software Developer:** The breadth of languages and technologies listed (Java, C, Python, JavaScript, etc.) and her understanding of fundamental computer science concepts (Data Structures, Algorithms, OOP) makes her a reasonable candidate for general software development roles, especially those involving web technologies.\n",
            "\n",
            "*   **Possible Fit (with further development):**\n",
            "    *   **Data Analyst:** Her resume shows some aptitude with Data Analysis and some use of Python. With the Face Recognition project, she shows some Machine Learning skills.\n",
            "    *   **Machine Learning Engineer:** She has some foundation in machine learning concepts, but would need a lot more focus in this area, plus deeper understanding and application of models, frameworks, and deployment strategies. The Face Recognition project is a good start.\n",
            "\n",
            "**Existing Skills (Strengths):**\n",
            "\n",
            "*   **Web Development (Front-End):** React, JavaScript, HTML/CSS, Tailwind CSS, Shadcn UI, React Hooks, Context API. Strong project-based experience in building interactive and responsive web applications.\n",
            "*   **Web Development (Back-End):** PHP, MySQL, Firebase, basic database knowledge.\n",
            "*   **Programming Fundamentals:** Java, C, Python, Data Structures & Algorithms, OOP.\n",
            "*   **Tools & Technologies:** Git, GitHub, VS Code, Docker, Android Studio, basic understanding of cloud platforms (Firebase).\n",
            "*   **Problem-Solving:** Evidenced by the design and implementation of complex projects like the Code Compiler and Face Recognition System.\n",
            "*   **Communication & Teamwork:** Listed soft skills, but should be demonstrated with examples.\n",
            "\n",
            "**Skills to Improve:**\n",
            "\n",
            "*   **Depth over Breadth:** The resume lists a wide range of technologies. It would be beneficial to demonstrate deeper expertise in a few key areas (e.g., React ecosystem, specific backend frameworks).\n",
            "*   **Testing:** No mention of testing methodologies or frameworks (e.g., Jest, Mocha, Cypress for JavaScript). Testing is a crucial skill for professional software development.\n",
            "*   **Backend Frameworks (Beyond PHP):** Explore modern backend frameworks like Node.js (Express), Python (Django/Flask), or Java (Spring Boot) to broaden back-end development skills. PHP is still used, but experience with more modern frameworks is highly desirable.\n",
            "*   **Database Experience:** While MySQL is listed, experience with other database technologies (e.g., PostgreSQL, MongoDB beyond Compass) and ORM (Object-Relational Mapping) libraries would be valuable.\n",
            "*   **Cloud Technologies:** Expand knowledge of cloud platforms (AWS, Azure, GCP) beyond basic Firebase hosting. Learn about services like compute instances, databases, and deployment tools.\n",
            "*   **Data Analysis and Machine Learning:** The Face Recognition project is a good start. Expand this by learning more about data cleaning, feature engineering, model selection, evaluation metrics, and deployment. Dive deeper into libraries like scikit-learn, TensorFlow, or PyTorch.\n",
            "*   **DevOps Practices:** While Docker is listed, consider learning about CI/CD (Continuous Integration/Continuous Deployment) pipelines, infrastructure as code (IaC) tools (e.g., Terraform, Ansible), and monitoring/logging.\n",
            "*   **Project Descriptions:** While good, could be improved. Quantify accomplishments whenever possible (e.g., \"Improved website performance by X% by implementing lazy loading\"). Focus on the *impact* of your work.\n",
            "\n",
            "**Recommended Courses/Certifications:**\n",
            "\n",
            "*   **Web Development:**\n",
            "    *   **Advanced React:** Focus on performance optimization, state management patterns (Redux, Zustand, Recoil), and testing. Look for courses on platforms like Udemy, Coursera, or Frontend Masters.\n",
            "    *   **Node.js (with Express):** Learn how to build RESTful APIs and backend services.\n",
            "    *   **Database Management:** Advanced SQL concepts, NoSQL databases (MongoDB), and ORM libraries.\n",
            "    *   **Testing:** Courses on Jest, Mocha, Cypress, or similar testing frameworks.\n",
            "*   **Data Analysis/Machine Learning:**\n",
            "    *   **Data Science Specialization (Coursera/edX):** Provides a comprehensive overview of data science concepts and tools.\n",
            "    *   **Machine Learning (Andrew Ng on Coursera):** A foundational course in machine learning.\n",
            "    *   **TensorFlow Developer Professional Certificate (Coursera) or PyTorch Certification:** Focus on deep learning frameworks.\n",
            "    *   **Specific courses on data cleaning, feature engineering, and model evaluation.**\n",
            "*   **Cloud Computing:**\n",
            "    *   **AWS Certified Cloud Practitioner or Azure Fundamentals:** Provides a good introduction to cloud concepts and services.\n",
            "    *   **Cloud-specific courses on web application deployment, database management, and serverless computing.**\n",
            "*   **DevOps:**\n",
            "    *   **CI/CD courses on platforms like Jenkins, GitLab CI, or CircleCI.**\n",
            "    *   **Infrastructure as Code (Terraform, Ansible) courses.**\n",
            "*   **LeetCode:** Should continue practicing on LeetCode, especially focusing on data structures and algorithms.\n",
            "\n",
            "**Key Strengths:**\n",
            "\n",
            "*   **Strong Academic Performance:** A CPI of 9.17 demonstrates a strong aptitude for computer science.\n",
            "*   **Hands-on Project Experience:** The projects showcase her ability to apply her skills to real-world problems.\n",
            "*   **Breadth of Technical Skills:** While depth is needed, the wide range of technologies listed shows a willingness to learn and explore different areas.\n",
            "*   **Proactive Learning:** The completion of multiple online courses and workshops demonstrates a commitment to continuous learning.\n",
            "\n",
            "**Key Weaknesses:**\n",
            "\n",
            "*   **Lack of Depth in Specific Areas:** The resume lists many technologies, but doesn't provide enough evidence of deep expertise in any one area.\n",
            "*   **Missing Key Skills:** Absence of testing experience is a significant gap.\n",
            "*   **Limited Cloud and DevOps Knowledge:** While Docker is a good start, more cloud and DevOps experience is needed for many professional roles.\n",
            "*   **Limited Real-World Experience:** The resume focuses on academic projects and certifications. An internship or open-source contributions would significantly strengthen her profile.\n",
            "\n",
            "**Recommendations:**\n",
            "\n",
            "1.  **Focus on Depth:** Choose 2-3 areas (e.g., React development, Node.js backend, or Python-based data analysis) and dive deep. Build more complex projects that showcase your expertise in these areas.\n",
            "2.  **Add Testing to Your Skillset:** Learn and practice testing methodologies and frameworks.\n",
            "3.  **Gain Practical Experience:** Look for internship opportunities or contribute to open-source projects to gain real-world experience.\n",
            "4.  **Quantify Your Accomplishments:** When describing your projects, use metrics to demonstrate the impact of your work.\n",
            "5.  **Tailor Your Resume:** Customize your resume for each job application, highlighting the skills and experiences that are most relevant to the specific role.\n",
            "6.  **Network:** Attend industry events, connect with professionals on LinkedIn, and participate in online communities to build your network.\n",
            "\n",
            "By addressing these areas, Dhvani can significantly improve her job prospects and position herself for a successful career in software development or data science.\n"
          ]
        }
      ],
      "source": [
        "# Print Analysis\n",
        "result = analyze_resume(resume_text)\n",
        "print(result)\n",
        "\n",
        "# Save Result to TXT file\n",
        "with open(\"/content/drive/MyDrive/Resume project/analysis2.txt\", \"w\") as file:\n",
        "    file.write(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_resume_jd(resume_text, job_description):\n",
        "    if not resume_text:\n",
        "        return {\"error\": \"Resume text is required for analysis.\"}\n",
        "    if not job_description:\n",
        "        return {\"error\": \"Job Description is required for analysis.\"}\n",
        "\n",
        "    model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
        "\n",
        "    base_prompt = f\"\"\"\n",
        "    You are an experienced HR with technical knowledge in one of these roles: Data Scientist, Data Analyst, DevOps Engineer, Machine Learning Engineer, Prompt Engineer, AI Engineer, Full Stack Web Developer, Big Data Engineer, Marketing Analyst, HR Manager, or Software Developer; review the provided resume and give a professional assessment on job fit, list existing skills, suggest skills to improve, recommend relevant courses, and highlight key strengths and weaknesses.\n",
        "\n",
        "    Resume:\n",
        "    {resume_text}\n",
        "    \"\"\"\n",
        "\n",
        "    if job_description:\n",
        "        base_prompt += f\"\"\"\n",
        "        Now, compare the candidate's resume with the job description below:\n",
        "\n",
        "        Job Description:\n",
        "        {job_description}\n",
        "\n",
        "        Your analysis should cover:\n",
        "          -How well the resume fits the job role\n",
        "          -Which skills match the job requirements\n",
        "          -Missing or underdeveloped skills\n",
        "          -Strengths and weaknesses related to the job\n",
        "          -Recommend relevant skills or certifications to improve the candidate's profile\n",
        "          -Suggest suitable courses or training programs based on gaps identified.\n",
        "          -Evaluate the candidate’s readiness for a technical role.\n",
        "          -List both technical and soft skills found in the resume.\n",
        "          -Suggest specific projects the candidate should complete to address gaps\n",
        "        \"\"\"\n",
        "\n",
        "    response = model.generate_content(base_prompt)\n",
        "\n",
        "    analysis = response.text.strip()\n",
        "    return analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Okay, here's a comprehensive assessment of Dhvani Kakadiya's resume against the AI/ML Instructor job description, considering my expertise as an HR professional with technical understanding:\n",
            "\n",
            "**Overall Job Fit Assessment:**\n",
            "\n",
            "Dhvani's resume indicates *potential*, but she's currently not a strong fit for the AI/ML Instructor role *as it is described*. While her coursework and projects demonstrate a good foundation in the necessary technical areas, she lacks the key requirement of \"1.5 years of experience in training students or professionals.\" Her resume focuses more on project development rather than teaching. She has strong technical capabilities to be a great student and learner, but it's not yet ready for the job description.\n",
            "\n",
            "**Skills Matching Job Requirements:**\n",
            "\n",
            "*   **Strong Conceptual Understanding (Partial):** Her coursework (\"Data Structures & Algorithms,\" \"Object-Oriented Programming,\" \"Database Management\") lays a foundation for understanding AI/ML concepts. Her projects also reflect basic understanding of ML algorithms and concepts.\n",
            "*   **Python & ML Libraries:** Her resume explicitly lists Python, OpenCV, scikit-learn, and NumPy, which are all crucial. The face recognition project further highlights this.\n",
            "*   **Cloud-Based Platforms:** Lists Google Colab and Jupyter Notebook.\n",
            "*   **AI/ML Techniques (Foundation):** Lists \"Machine Learning,\" \"Data Analysis\" - indicates familiarity with the terms and concepts, further elaborated on the projects.\n",
            "\n",
            "**Missing or Underdeveloped Skills:**\n",
            "\n",
            "*   **Teaching/Mentoring Experience:** This is the biggest gap. The resume doesn't show any formal teaching, training, or mentoring experience.\n",
            "*   **Deep Learning Frameworks:** While she lists \"Machine Learning,\" there's no explicit mention of TensorFlow or PyTorch (though FaceNet in the face recognition project implies *some* knowledge of deep learning).\n",
            "*   **NLP Libraries:** The resume doesn't list any specific NLP libraries.\n",
            "*   **Generative AI:** No mention of Generative AI concepts or experience with LLMs.\n",
            "*   **Model Deployment:** No mention of Flask, FastAPI, or Streamlit.\n",
            "\n",
            "**Strengths:**\n",
            "\n",
            "*   **Strong Academic Record:** High CPI and percentage scores indicate a strong aptitude for learning.\n",
            "*   **Project-Based Learning:** She has a diverse range of projects demonstrating hands-on experience. The projects cover web development and machine learning.\n",
            "*   **Tech Stack Familiarity:** Lists a good range of relevant technologies and tools.\n",
            "*   **Fast Learner:** As per the projects completed by her, she is a fast learner and has good hands-on experience with all relevant languages.\n",
            "\n",
            "**Weaknesses:**\n",
            "\n",
            "*   **Lack of Teaching/Training Experience:** A significant gap for an instructor role.\n",
            "*   **Limited AI/ML Depth:** While she has some ML experience, the projects showcase foundational understanding more than advanced skills. No mention of experience with deep learning frameworks or large language models.\n",
            "*   **No Model Deployment Experience:** This is a valuable skill for demonstrating real-world application.\n",
            "*   **Resume Formatting:** While the content is good, the formatting is a bit basic. It could be improved for better readability.\n",
            "*   **Lack of experience with a proper working environment.**\n",
            "\n",
            "**Recommendations for Improvement:**\n",
            "\n",
            "*   **Gain Teaching/Mentoring Experience:**\n",
            "    *   Volunteer as a tutor or mentor at a local school or coding bootcamp.\n",
            "    *   Offer workshops or tutorials on AI/ML topics to fellow students.\n",
            "    *   Create and share educational content (blog posts, videos) on AI/ML concepts.\n",
            "*   **Deepen AI/ML Skills:**\n",
            "    *   Focus on learning TensorFlow and PyTorch.\n",
            "    *   Explore NLP libraries like NLTK, SpaCy, or transformers.\n",
            "    *   Dive into Generative AI and LLMs through projects and courses.\n",
            "*   **Develop Model Deployment Skills:**\n",
            "    *   Learn Flask, FastAPI, or Streamlit to deploy ML models as web applications.\n",
            "*   **Build Portfolio Projects:**\n",
            "    *   Create projects that demonstrate teaching ability (e.g., a project that builds a simple ML model and then explains it clearly for beginners).\n",
            "    *   Work on projects that involve deep learning, NLP, and Generative AI.\n",
            "    *   Deploy a model using Flask/FastAPI and host it online.\n",
            "*   **Consider Certifications:**\n",
            "    *   TensorFlow Developer Certification\n",
            "    *   AWS Certified Machine Learning – Specialty\n",
            "    *   Coursera Machine Learning Specialization (Andrew Ng)\n",
            "\n",
            "**Suitable Courses/Training Programs:**\n",
            "\n",
            "*   **Deep Learning Specialization (Coursera):** Comprehensive introduction to deep learning.\n",
            "*   **TensorFlow/PyTorch Tutorials (Official Documentation):** Best way to learn the frameworks.\n",
            "*   **NLP Course (Stanford/Coursera):** In-depth coverage of NLP techniques.\n",
            "*   **Generative AI Courses (Coursera/Udacity):** Specifically targeting LLMs and related concepts.\n",
            "*   **Flask/FastAPI Tutorials (Real Python, YouTube):** Learn to deploy models.\n",
            "*   **Instructional Design Courses (Coursera/edX):** For developing effective teaching skills.\n",
            "\n",
            "**Candidate's Readiness for a Technical Role:**\n",
            "\n",
            "Based on the resume, Dhvani is a strong candidate for an **entry-level technical role** such as a Data Scientist Intern, Machine Learning Engineer Intern, or Junior AI Engineer. Her project experience and coursework indicate a solid foundation. However, she needs more practical experience and specific skill development to be competitive for a mid-level or senior role.\n",
            "\n",
            "**Technical and Soft Skills:**\n",
            "\n",
            "*   **Technical Skills:** Java, C, MySQL, Python, Javascript, Dart, ruby(Basic), HTML/CSS, PHP, Bootstrap/Tailwind, Firebase, Machine learning, Data analysis, Reactjs, Git, GitHub, VS Code, Android Studio, Docker, Xampp, Apache Netbeans, Google Colab, Anaconda, Jupyter Notebook, nmap, MongoDB compass, OpenCV, HaarCascades, Dlib, FaceNet, NumPy, Tkinter, scikit-learn, SQLite, Matplotlib\n",
            "*   **Soft Skills:** Communication, Problem-solving, Teamwork, Concentration\n",
            "\n",
            "**Specific Project Suggestions to Address Gaps:**\n",
            "\n",
            "1.  **\"AI/ML for Beginners\" Project:**\n",
            "    *   *Goal:* Demonstrate the ability to explain complex concepts simply.\n",
            "    *   *Description:* Build a basic image classifier using TensorFlow/Keras (e.g., classifying cats vs. dogs). Create a companion website or documentation explaining the project in beginner-friendly terms. Focus on explaining the *why* behind each step, not just the *how*.\n",
            "2.  **\"Sentiment Analysis API with Deployment\":**\n",
            "    *   *Goal:* Learn NLP and model deployment.\n",
            "    *   *Description:* Build a sentiment analysis model using a pre-trained transformer (e.g., BERT). Deploy it as an API using Flask/FastAPI. Create a simple front-end interface to test the API.\n",
            "3.  **\"Generative AI Content Creation Project\":**\n",
            "    *   *Goal:* Gain experience with Generative AI.\n",
            "    *   *Description:* Use a pre-trained LLM (e.g., GPT-2, GPT-3) to generate creative content (e.g., poems, stories, code snippets). Fine-tune the model on a specific dataset to customize the output. Document the process and challenges.\n",
            "\n",
            "**Summary:**\n",
            "\n",
            "Dhvani possesses a strong foundation in computer science and shows potential in AI/ML. However, she needs to actively pursue teaching/mentoring opportunities and deepen her AI/ML skillset to become a viable candidate for an AI/ML Instructor role. Focus on projects that demonstrate teaching ability, deep learning, NLP, and model deployment.\n"
          ]
        }
      ],
      "source": [
        "# Print Analysis\n",
        "result_jd = analyze_resume_jd(resume_text, job_description)\n",
        "print(result_jd)\n",
        "\n",
        "# Save Result to TXT file\n",
        "with open(\"/content/drive/MyDrive/Resume project/analysis1.txt\", \"w\") as file:\n",
        "    file.write(result_jd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
